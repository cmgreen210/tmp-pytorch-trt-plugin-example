[04/15/2025-09:30:57] [TRT] [W] Functionality provided through tensorrt.plugin module is experimental.
/home/chris/workspace/triton-test/.venv/lib/python3.12/site-packages/torch_tensorrt/fx/tracer/acc_tracer/acc_ops.py:895: UserWarning: Unable to import torchvision related libraries.: No module named 'torchvision'. Please install torchvision lib in order to lower stochastic_depth
  warnings.warn(
Unable to import quantization op. Please install modelopt library (https://github.com/NVIDIA/TensorRT-Model-Optimizer?tab=readme-ov-file#installation) to add support for compiling quantized models
TensorRT-LLM is not installed. Please install TensorRT-LLM or set TRTLLM_PLUGINS_PATH to the directory containing libnvinfer_plugin_tensorrt_llm.so to use converters for torch.distributed ops
Plugin registration function: 

def add_plugin_desc(X):
    return _generic_plugin_desc(X)
    
Plugin implementation function: 

def add_plugin_impl(X, outputs, stream):
    _generic_plugin_impl(outputs, stream, X)
    
DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:
graph():
    %x : [num_users=1] = placeholder[target=x]
    %add_one : [num_users=1] = call_function[target=torch.ops.my.add_one.default](args = (%x,), kwargs = {})
    return (add_one,)
DEBUG:torch_tensorrt.dynamo._compiler:Input graph: graph():
    %x : [num_users=1] = placeholder[target=x]
    %add_one : [num_users=1] = call_function[target=torch.ops.my.add_one.default](args = (%x,), kwargs = {})
    return (add_one,)
DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:
graph():
    %x : [num_users=1] = placeholder[target=x]
    %add_one : [num_users=1] = call_function[target=torch.ops.my.add_one.default](args = (%x,), kwargs = {})
    return (add_one,)
DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_assert_nodes:Removed 0 assert_scalar nodes:
graph():
    %x : [num_users=1] = placeholder[target=x]
    %add_one : [num_users=1] = call_function[target=torch.ops.my.add_one.default](args = (%x,), kwargs = {})
    return (add_one,)
DEBUG:torch_tensorrt.dynamo.lowering.passes.accumulate_fp32_matmul:Skipping FP32 accumulation for matmul layers as use_fp32_acc is not enabled in the compilation settings
DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_num_users_is_0_nodes:Removed ops that [num_users=0] nodes:
graph():
    %x : [num_users=1] = placeholder[target=x]
    %add_one : [num_users=1] = call_function[target=torch.ops.my.add_one.default](args = (%x,), kwargs = {})
    return (add_one,)
DEBUG:torch_tensorrt.dynamo._compiler:Lowered Input graph: graph():
    %x : [num_users=1] = placeholder[target=x]
    %add_one : [num_users=1] = call_function[target=torch.ops.my.add_one.default](args = (%x,), kwargs = {})
    return (add_one,)
DEBUG:torch_tensorrt.dynamo.conversion._ConverterRegistry:Converter options for my.add_one.default: 1
DEBUG:torch_tensorrt.dynamo.conversion._ConverterRegistry:Selecting converter option 0 for converting my.add_one.default
DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:
Supported Nodes:
- torch.ops.my.add_one.default + Operator Count: 1

DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:
All Nodes Supported

DEBUG:torch_tensorrt.dynamo._compiler:Detected support for 1 operators out of 1 in subgraph.
INFO:torch_tensorrt.dynamo._compiler:Partitioning the graph via the fast partitioner
DEBUG:torch_tensorrt.dynamo.conversion._ConverterRegistry:Converter options for my.add_one.default: 1
DEBUG:torch_tensorrt.dynamo.conversion._ConverterRegistry:Selecting converter option 0 for converting my.add_one.default
DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:
Number of TensorRT-Accelerated Engines Generated: 1
DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:
Supported Nodes:
- torch.ops.my.add_one.default + Operator Count: 1

DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:
All Nodes Supported

DEBUG:torch_tensorrt.dynamo._compiler:Updated metadata for node: _run_on_acc_0 with its corresponding submodule outputs
DEBUG:torch_tensorrt.dynamo._compiler:Converting submodule: _run_on_acc_0
 Input shapes: [(64, 64)]
 graph():
    %x : [num_users=1] = placeholder[target=x]
    %add_one : [num_users=1] = call_function[target=torch.ops.my.add_one.default](args = (%x,), kwargs = {})
    return add_one
WARNING:py.warnings:/home/chris/workspace/triton-test/.venv/lib/python3.12/site-packages/torch_tensorrt/dynamo/utils.py:423: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(tensor).dtype

INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 212, GPU 1151 (MiB)
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Trying to load shared library libnvinfer_builder_resource.so.10.9.0
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Loaded shared library libnvinfer_builder_resource.so.10.9.0
INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageChange] Init builder kernel library: CPU +2773, GPU +444, now: CPU 3186, GPU 1595 (MiB)
DEBUG:torch_tensorrt [TensorRT Conversion Context]:CUDA lazy loading is enabled.
DEBUG:torch_tensorrt.dynamo.conversion._ConverterRegistry:Converter options for my.add_one.default: 1
DEBUG:torch_tensorrt.dynamo.conversion._ConverterRegistry:Selecting converter option 0 for converting my.add_one.default
DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node x (kind: x, args: ())
DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: x [shape=[64, 64], dtype=DataType.FLOAT]
INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node x [x] (Inputs: () | Outputs: (x: (64, 64)@torch.float32))
DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node /add_one (kind: my.add_one.default, args: ('x <Node>',))
DEBUG:torch_tensorrt.dynamo.conversion._ConverterRegistry:Converter options for my.add_one.default: 1
DEBUG:torch_tensorrt.dynamo.conversion._ConverterRegistry:Selecting converter option 0 for converting my.add_one.default
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Global registry found add_one creator.
INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node /add_one [my.add_one.default] (Inputs: (x: (64, 64)@torch.float32) | Outputs: (add_one: (64, 64)@torch.float32))
DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node output (kind: output, args: ('add_one <Node>',))
DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output0 [shape=(64, 64), dtype=DataType.FLOAT]
INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converted node output [output] (Inputs: (add_one: (64, 64)@torch.float32) | Outputs: (output: ))
INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.080783
INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Not found cached TRT engines. Start building engine.
WARNING:torch_tensorrt [TensorRT Conversion Context]:sizeInBytes -1 should not be negative value, IBuilderConfig::setL2LimitForTiling(-1) has no effect.
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Loaded 33 timing cache entries.
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Loaded 4382 bytes of code generator cache.
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Loaded 834166 bytes of compilation cache.
[0G[2K[----------] Building engine 0/6
[1A[0G[2K[----------] Building engine 0/6
[2K [----------] Cloning network graph 0/3
[2A[0G[2K[----------] Building engine 0/6
[2K [----------] Cloning network graph 0/3
[2A[0G[2K[----------] Building engine 0/6
[2K [===-------] Cloning network graph 1/3
[2A[0G[2K[----------] Building engine 0/6
[2K [======----] Cloning network graph 2/3
[2A[0G[2K[----------] Building engine 0/6
[2K
[2A[0G[2K[----------] Building engine 0/6
[1A[0G[2K[=---------] Building engine 1/6
[1A[0G[2K[=---------] Building engine 1/6
[2K [----------] Preparing graph for optimization 0/4
[2ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Original: 1 layers
[0G[2K[=---------] Building engine 1/6
[2K [----------] Preparing graph for optimization 0/4
[2ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After dead-layer removal: 1 layers
DEBUG:torch_tensorrt [TensorRT Conversion Context]:SYMBOLIC CHECKS
DEBUG:torch_tensorrt [TensorRT Conversion Context]:GRAPH NODES
DEBUG:torch_tensorrt [TensorRT Conversion Context]:PLUGIN_V3 [my.add_one.default]-[/add_one]
DEBUG:torch_tensorrt [TensorRT Conversion Context]:    Input 0
DEBUG:torch_tensorrt [TensorRT Conversion Context]:        64	64
DEBUG:torch_tensorrt [TensorRT Conversion Context]:        64	64
DEBUG:torch_tensorrt [TensorRT Conversion Context]:    Output 0
DEBUG:torch_tensorrt [TensorRT Conversion Context]:        64	64
DEBUG:torch_tensorrt [TensorRT Conversion Context]:        64	64
[0G[2K[=---------] Building engine 1/6
[2K [==--------] Preparing graph for optimization 1/4
[2A[0G[2K[=---------] Building engine 1/6
[2K [=====-----] Preparing graph for optimization 2/4
[2A[0G[2K[=---------] Building engine 1/6
[2K [=======---] Preparing graph for optimization 3/4
[2A[0G[2K[=---------] Building engine 1/6
[2K
[2A[0G[2K[===-------] Building engine 2/6
[1ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Graph construction completed in 0.015868 seconds.
[0G[2K[=====-----] Building engine 3/6
[1A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Optimizing graph 0/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Optimizing graph 0/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After adding DebugOutput nodes: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Optimizing graph 1/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Optimizing graph 2/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Optimizing graph 3/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=---------] Optimizing graph 4/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=---------] Optimizing graph 5/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After Myelin optimization: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=---------] Optimizing graph 6/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [==--------] Optimizing graph 7/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [==--------] Optimizing graph 8/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [==--------] Optimizing graph 9/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [===-------] Optimizing graph 10/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [===-------] Optimizing graph 11/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Applying ScaleNodes fusions.
DEBUG:torch_tensorrt [TensorRT Conversion Context]:After scale fusion: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [===-------] Optimizing graph 12/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [===-------] Optimizing graph 13/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [====------] Optimizing graph 14/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [====------] Optimizing graph 15/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [====------] Optimizing graph 16/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=====-----] Optimizing graph 17/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After dupe layer removal: 1 layers
DEBUG:torch_tensorrt [TensorRT Conversion Context]:After final dead-layer removal: 1 layers
DEBUG:torch_tensorrt [TensorRT Conversion Context]:After tensor merging: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=====-----] Optimizing graph 18/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=====-----] Optimizing graph 19/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After vertical fusions: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [======----] Optimizing graph 20/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After dupe layer removal: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [======----] Optimizing graph 21/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After final dead-layer removal: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [======----] Optimizing graph 22/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After tensor merging: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [======----] Optimizing graph 23/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After slice removal: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=======---] Optimizing graph 24/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:After concat removal: 1 layers
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=======---] Optimizing graph 25/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [=======---] Optimizing graph 26/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Trying to split Reshape and strided tensor
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [========--] Optimizing graph 27/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [========--] Optimizing graph 28/33
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [========--] Optimizing graph 29/33
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Graph optimization time: 0.00273896 seconds.
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Building graph using backend strategy 2
INFO:torch_tensorrt [TensorRT Conversion Context]:Global timing cache in use. Profiling results in this builder pass will be stored.
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Constructing optimization profile number 0 [1/1].
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Applying generic optimizations to the graph for inference.
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Reserving memory for host IO tensors. Host: 0 bytes
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[4A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [----------] Timing graph nodes 0/3
[5A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [----------] Timing graph nodes 0/3
[5ADEBUG:torch_tensorrt [TensorRT Conversion Context]:=============== Computing costs for [my.add_one.default]-[/add_one]
DEBUG:torch_tensorrt [TensorRT Conversion Context]:[my.add_one.default]-[/add_one] [Float(64,1) -> Float(64,1)] got cached result: PluginV3, tactic 0x0000000000000000, 0 ms
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [===-------] Timing graph nodes 1/3
[5A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [======----] Timing graph nodes 2/3
[5A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K
[5A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[4A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [----------] Timing tensor reformats 0/3
[5ADEBUG:torch_tensorrt [TensorRT Conversion Context]:=============== Computing reformatting costs for available format set
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [----------] Timing tensor reformats 0/3
[2K     [----------] Computing reformatting costs 0/1
[6A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [----------] Timing tensor reformats 0/3
[2K     [----------] Computing reformatting costs 0/1
[6A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [----------] Timing tensor reformats 0/3
[2K
[6A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [----------] Timing tensor reformats 0/3
[5A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [===-------] Timing tensor reformats 1/3
[5ADEBUG:torch_tensorrt [TensorRT Conversion Context]:=============== Computing reformatting costs for available format set
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [===-------] Timing tensor reformats 1/3
[2K     [----------] Computing reformatting costs 0/1
[6A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [===-------] Timing tensor reformats 1/3
[2K     [----------] Computing reformatting costs 0/1
[6A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [===-------] Timing tensor reformats 1/3
[2K
[6A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K    [======----] Timing tensor reformats 2/3
[5A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [----------] Timing tactics 0/3
[2K
[5A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K   [===-------] Timing tactics 1/3
[4A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[2K
[4A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [----------] Computing profile costs 0/5
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [==--------] Computing profile costs 1/5
[3ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Formats and tactics selection completed in 0.00280804 seconds.
DEBUG:torch_tensorrt [TensorRT Conversion Context]:After reformat layers: 1 layers
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Total number of blocks in pre-optimized block assignment: 1
INFO:torch_tensorrt [TensorRT Conversion Context]:Detected 1 inputs and 1 output network tensors.
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [====------] Computing profile costs 2/5
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [====------] Computing profile costs 2/5
[2K   [----------] Determining refit engines 0/1
[4A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [====------] Computing profile costs 2/5
[2K   [----------] Determining refit engines 0/1
[4A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [======----] Computing profile costs 3/5
[2K   [----------] Determining refit engines 0/1
[4ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Layer: [my.add_one.default]-[/add_one] Host Persistent: 388 bytes Device Persistent: 0 bytes Scratch Memory: 0 bytes
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Skipped printing memory information for 0 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
INFO:torch_tensorrt [TensorRT Conversion Context]:Total Host Persistent Memory: 400 bytes
INFO:torch_tensorrt [TensorRT Conversion Context]:Total Device Persistent Memory: 0 bytes
INFO:torch_tensorrt [TensorRT Conversion Context]:Max Scratch Memory: 0 bytes
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Total number of blocks in optimized block assignment: 0
INFO:torch_tensorrt [TensorRT Conversion Context]:Total Activation Memory: 0 bytes
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [========--] Computing profile costs 4/5
[2K   [----------] Determining refit engines 0/1
[4A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K  [========--] Computing profile costs 4/5
[2K
[4AINFO:torch_tensorrt [TensorRT Conversion Context]:Total Weights Memory: 0 bytes
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Total number of generated kernels selected for the engine: 0
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Disabling unused tactic source: EDGE_MASK_CONVOLUTIONS
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Disabling unused tactic source: JIT_CONVOLUTIONS
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Initializing plugin at: allocateResources
INFO:torch_tensorrt [TensorRT Conversion Context]:Engine generation completed in 0.0126888 seconds.
[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2K
[3A[0G[2K[=====-----] Building engine 3/6
[2K [----------] Building engine from subgraph 0/1
[2A[0G[2K[=====-----] Building engine 3/6
[2K
[2A[0G[2K[======----] Building engine 4/6
[1ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Layers:
Name: [my.add_one.default]-[/add_one], LayerType: PluginV3, Inputs: [ { Name: x, Location: Device, Dimensions: [64,64], Format/Datatype: Float }], Outputs: [ { Name: output0, Location: Device, Dimensions: [64,64], Format/Datatype: Float }], PluginType: add_one, PluginVersion: "1", PluginMetadata: "[Metadata not provided by plugin]", TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 

Bindings:
x
output0
INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 0 MiB
[0G[2K
[1ADEBUG:torch_tensorrt [TensorRT Conversion Context]:Adding 1 engine(s) to plan file.
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Adding 1 engine weights(s) to plan file.
INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:00.040852
INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 7540 bytes of Memory
DEBUG:torch_tensorrt [TensorRT Conversion Context]:Serializing timing cache. UUID = GPU-34f32802-e018-0316-f6d3-7b7fef435699, commit ID = 9406843d50261530
INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 4382 bytes of code generator cache.
INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 834166 bytes of compilation cache.
INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 33 timing cache entries
DEBUG: [Torch-TensorRT] - Deserializing Device Info: 0%8%9%0%NVIDIA GeForce RTX 4070 Laptop GPU
DEBUG: [Torch-TensorRT] - Deserialized Device Info: Device(ID: 0, Name: NVIDIA GeForce RTX 4070 Laptop GPU, SM Capability: 8.9, Type: GPU)
DEBUG: [Torch-TensorRT] - Target Device: Device(ID: 0, Name: NVIDIA GeForce RTX 4070 Laptop GPU, SM Capability: 8.9, Type: GPU)
DEBUG: [Torch-TensorRT] - Setting Device(ID: 0, Name: NVIDIA GeForce RTX 4070 Laptop GPU, SM Capability: 8.9, Type: GPU) as active device
INFO: [Torch-TensorRT] - Loaded engine size: 0 MiB
DEBUG: [Torch-TensorRT] - Initializing plugin at: allocateResources
DEBUG: [Torch-TensorRT] - Deserialization required 185 microseconds.
DEBUG: [Torch-TensorRT] - Total per-runner device persistent memory is 0
DEBUG: [Torch-TensorRT] - Total per-runner host persistent memory is 400
DEBUG: [Torch-TensorRT] - Allocated device scratch memory of size 0
DEBUG: [Torch-TensorRT] - - Runner scratch: 0 bytes
INFO: [Torch-TensorRT] - [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
DEBUG: [Torch-TensorRT] - CUDA lazy loading is enabled.
DEBUG: [Torch-TensorRT] - Input binding name: x has TensorRT binding index: 0, Torch binding index: 0
DEBUG: [Torch-TensorRT] - Output binding name: output0 has TensorRT binding index: 1, Torch binding index: 1
DEBUG: [Torch-TensorRT] - Torch-TensorRT TensorRT Engine:
  Name: _run_on_acc_0_engine
  Inputs: [
    id: 0
      name: x
      shape: [64, 64]
      dtype: Float
  ]
  Outputs: [
    id: 0
      name: output0
      shape: [64, 64]
      dtype: Float
  ]
  Device: Device(ID: 0, Name: NVIDIA GeForce RTX 4070 Laptop GPU, SM Capability: 8.9, Type: GPU)
  Hardware Compatibility: Disabled
  Target Platform: linux_x86_64

DEBUG:torch_tensorrt.dynamo._DryRunTracker:
++++++++++++++++++++++++++++++++++++++++++++++++++ Dry-Run Results for Graph ++++++++++++++++++++++++++++++++++++++++++++++++++

The graph consists of 1 Total Operators, of which 1 operators are supported, 100.0% coverage

Compiled with: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=0, min_block_size=1, torch_executed_ops=set(), pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False, timing_cache_path='/tmp/torch_tensorrt_engine_cache/timing_cache.bin', lazy_engine_init=False, cache_built_engines=False, reuse_cached_engines=False, use_explicit_typing=False, use_fp32_acc=False, refit_identical_engine_weights=False, strip_engine_weights=False, immutable_weights=True, enable_weight_streaming=False, enable_cross_compile_for_windows=False, tiling_optimization_level='none', l2_limit_for_tiling=-1, use_distributed_mode_trace=False)

  Graph Structure:

   Inputs: List[Tensor: (64, 64)@float32]
    ...
    TRT Engine #1 - Submodule name: _run_on_acc_0
     Engine Inputs: List[Tensor: (64, 64)@float32]
     Number of Operators in Engine: 1
     Engine Outputs: List[Tensor: (64, 64)@float32]
    ...
   Outputs: List[Tensor: (64, 64)@float32]

  ------------------------- Aggregate Stats -------------------------

   Average Number of Operators per TRT Engine: 1.0
   Most Operators in a TRT Engine: 1

  ********** Recommendations **********

   - For minimal graph segmentation, select min_block_size=1 which would generate 1 TRT engine(s)
   - The current level of graph segmentation is equivalent to selecting min_block_size=1 which generates 1 TRT engine(s)
DEBUG: [Torch-TensorRT] - Attempting to run engine (ID: _run_on_acc_0_engine); Hardware Compatible: 0
DEBUG: [Torch-TensorRT] - Using the standard execution runtime mode with cudagraphs=0.
DEBUG: [Torch-TensorRT] - Input shape changed None -> (64,64)
DEBUG: [Torch-TensorRT] - Input Name: x Shape: [64, 64]
DEBUG: [Torch-TensorRT] - Output Name: output0 Shape: [64, 64]
